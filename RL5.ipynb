{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq/6LwSBcKJwqt6z0FIGRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohrehFeridoun/RL_ex5/blob/main/RL5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy_qjjpMNIT6",
        "outputId": "f5ec2e41-e720-4d8e-c352-96142b019126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "\n",
        "env=gym.make(\"FrozenLake8x8-v1\")"
      ],
      "metadata": {
        "id": "UepZtYA2NJnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "columns_size = env.action_space.n\n",
        "rows_size = env.observation_space.n\n",
        "\n",
        "q_table = np.zeros((rows_size , columns_size))\n",
        "q_table_copy = copy.deepcopy(q_table)\n",
        "\n",
        "print(q_table_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-PGhQsSNOyS",
        "outputId": "da549d65-9181-47d2-b32d-608c0dee0973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "num_episodes = 10000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "exploration_rate = 1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.001\n",
        "epsilon_min = 0.05\n",
        "\n",
        "# Train the agent\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    step = 0\n",
        "\n",
        "    while not done and step < max_steps_per_episode:\n",
        "        # Exploration-exploitation trade-off\n",
        "        exploration_rate_threshold = random.uniform(0, 1)\n",
        "        if exploration_rate_threshold > exploration_rate:\n",
        "            action = np.argmax(q_table[state, :])\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        # Take new action\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # Update Q-table\n",
        "        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n",
        "            learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
        "\n",
        "        # Update state and step\n",
        "        state = new_state\n",
        "        step += 1\n",
        "\n",
        "    # Decay exploration rate\n",
        "    exploration_rate = min_exploration_rate + \\\n",
        "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)"
      ],
      "metadata": {
        "id": "n7_iUBY_Nyuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to track rewards\n",
        "rewards_all_episodes = []\n",
        "\n",
        "# Q-learning algorithm\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset() # reset for each new episode\n",
        "    done = False # keep track whether or not the episode finishes, start=False\n",
        "    rewards_current_episode = 0 # track reward, start=0\n",
        "\n",
        "    # Loop for each step in the episode\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Exploration & exploitation trade-off\n",
        "        exploration_rate_threshold = random.uniform(0, 1) # create random number (r) at each time step\n",
        "        if exploration_rate_threshold > exploration_rate:\n",
        "            action = np.argmax(q_table[state, :])\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        new_state, reward, done, info = env.step(action) # apply action & get results\n",
        "\n",
        "        # Update Q-table\n",
        "        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n",
        "            learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
        "\n",
        "        state = new_state\n",
        "        rewards_current_episode += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Decay exploration rate\n",
        "    exploration_rate = min_exploration_rate + \\\n",
        "        (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)\n",
        "\n",
        "    rewards_all_episodes.append(rewards_current_episode)"
      ],
      "metadata": {
        "id": "nPk44mi9OWiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print average reward per thousand episodes\n",
        "rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes), num_episodes/1000)\n",
        "count = 1000\n",
        "print(\"Average reward per thousand episodes\\n\")\n",
        "for r in rewards_per_thousand_episodes:\n",
        "    print(count, ':', str(sum(r/1000)))\n",
        "    count += 1000\n",
        "\n",
        "# Print updated Q table\n",
        "print('\\n\\nQ-table\\n')\n",
        "print(q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8kk0mOHOu-D",
        "outputId": "63a6419c-00b7-4375-bd33-c6aabd517f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average reward per thousand episodes\n",
            "\n",
            "1000 : 0.025000000000000015\n",
            "2000 : 0.17000000000000012\n",
            "3000 : 0.33600000000000024\n",
            "4000 : 0.4940000000000004\n",
            "5000 : 0.5100000000000003\n",
            "6000 : 0.5410000000000004\n",
            "7000 : 0.5040000000000003\n",
            "8000 : 0.5570000000000004\n",
            "9000 : 0.5220000000000004\n",
            "10000 : 0.5510000000000004\n",
            "\n",
            "\n",
            "Q-table\n",
            "\n",
            "[[3.69451484e-01 3.69223794e-01 3.73492212e-01 3.69383953e-01]\n",
            " [3.77004356e-01 3.76861965e-01 3.77343563e-01 3.94221202e-01]\n",
            " [3.96450335e-01 3.97930546e-01 4.13049420e-01 3.97435704e-01]\n",
            " [4.15882285e-01 4.16192917e-01 4.29047371e-01 4.16176964e-01]\n",
            " [4.40315218e-01 4.40484135e-01 4.63132252e-01 4.41553321e-01]\n",
            " [4.64299202e-01 4.66436861e-01 4.89043655e-01 4.66569288e-01]\n",
            " [4.79181007e-01 4.80957087e-01 5.05094998e-01 4.86521758e-01]\n",
            " [4.86240379e-01 5.08967564e-01 4.90861810e-01 4.85651870e-01]\n",
            " [3.66803535e-01 3.66844976e-01 3.66965619e-01 3.72911348e-01]\n",
            " [3.73131722e-01 3.73688264e-01 3.82989708e-01 3.73809099e-01]\n",
            " [3.82204794e-01 3.83919677e-01 3.84172787e-01 3.98999035e-01]\n",
            " [2.60557733e-01 1.98943300e-01 2.65055210e-01 4.26760396e-01]\n",
            " [4.19755221e-01 4.26961677e-01 4.24540750e-01 4.54156828e-01]\n",
            " [4.56849891e-01 4.52310080e-01 4.83885277e-01 4.61994662e-01]\n",
            " [4.88286212e-01 4.88987087e-01 5.23310159e-01 4.85288235e-01]\n",
            " [4.96243990e-01 4.97182214e-01 5.36094720e-01 4.98547945e-01]\n",
            " [3.56822155e-01 3.56668088e-01 3.56987125e-01 3.61377580e-01]\n",
            " [3.45072322e-01 3.44325525e-01 3.42757881e-01 3.56641552e-01]\n",
            " [3.32201205e-01 2.78692450e-01 1.87414304e-01 2.44473520e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.55949238e-01 1.72193599e-01 4.04054973e-01 3.04350929e-01]\n",
            " [3.44211772e-01 3.93372137e-01 4.02939220e-01 4.72674359e-01]\n",
            " [4.92548363e-01 4.94274009e-01 5.55030885e-01 5.01191064e-01]\n",
            " [5.27176017e-01 5.92600396e-01 5.30435336e-01 5.23044716e-01]\n",
            " [3.29634942e-01 3.29494072e-01 3.29906001e-01 3.44005318e-01]\n",
            " [3.16543240e-01 3.06746724e-01 2.96143955e-01 3.09329415e-01]\n",
            " [2.49116509e-01 2.20952141e-01 2.26198466e-01 2.37239040e-01]\n",
            " [8.86790031e-02 1.55413513e-01 6.64445867e-02 1.10390943e-01]\n",
            " [2.60403262e-01 1.24650169e-01 1.73179621e-01 1.37613673e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [3.39334183e-01 2.85381603e-01 5.91529358e-01 3.71683140e-01]\n",
            " [5.69990024e-01 5.53375163e-01 6.49825339e-01 5.48906519e-01]\n",
            " [2.89690680e-01 2.37920556e-01 2.52933738e-01 3.00314934e-01]\n",
            " [2.11424705e-01 1.45329846e-01 2.11793598e-01 2.61776373e-01]\n",
            " [1.28809262e-01 1.04648294e-01 6.02754387e-02 1.33723054e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.24970001e-01 8.72863372e-02 1.79528359e-01 1.60693859e-01]\n",
            " [1.16273903e-01 2.16509980e-01 1.55938540e-01 1.71824151e-01]\n",
            " [2.92694674e-01 3.23878748e-01 3.85267310e-01 5.00202166e-01]\n",
            " [5.76842081e-01 6.05008589e-01 7.20395071e-01 6.04562615e-01]\n",
            " [2.01829208e-01 2.15998264e-02 6.72291644e-02 7.80874557e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.43052858e-11 2.34154895e-02 3.30230622e-02 0.00000000e+00]\n",
            " [5.98521318e-02 2.62655738e-02 1.16032717e-01 7.10267209e-02]\n",
            " [1.48158169e-01 1.67917028e-02 4.64217881e-02 7.23867055e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [6.92504361e-01 5.17220574e-01 7.76955796e-01 4.63448062e-01]\n",
            " [1.75149761e-02 3.97894061e-04 3.61997873e-02 6.91133275e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.52886051e-13 0.00000000e+00 2.95173125e-03 0.00000000e+00]\n",
            " [1.20408561e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.04364498e-02 2.98871023e-03 5.88699513e-02 1.32753829e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [6.20561580e-01 5.83109021e-01 8.81305900e-01 3.99607763e-01]\n",
            " [1.14792788e-02 6.15948740e-04 4.56016383e-05 1.43504043e-03]\n",
            " [1.87290647e-03 2.71303088e-12 3.75325975e-05 2.74043523e-11]\n",
            " [8.38137619e-04 1.21676020e-12 1.46965961e-13 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [3.17256823e-04 0.00000000e+00 0.00000000e+00 1.10799216e-02]\n",
            " [2.73476347e-02 2.31361288e-03 3.76707969e-03 4.18512013e-03]\n",
            " [6.71324663e-03 0.00000000e+00 3.69915127e-04 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the agent actually play\n",
        "for episode in range(3):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    print(\"Episode\", episode+1, \"\\n\")\n",
        "    time.sleep(1)\n",
        "\n",
        "    for step in range(max_steps_per_episode):\n",
        "        clear_output(wait=True) # clear output for another output printout,for visual smoothness\n",
        "        print(env.render(mode=\"ansi\")) # see where agent is on the grid\n",
        "        time.sleep(0.3)\n",
        "\n",
        "        action = np.argmax(q_table[state, :])\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            clear_output(wait=True)\n",
        "            print(env.render(mode=\"ansi\"))\n",
        "            if reward == 1:\n",
        "                print('Win')\n",
        "                time.sleep(3)\n",
        "            else:\n",
        "                print('Fell hole')\n",
        "                time.sleep(3)\n",
        "            clear_output(wait=True)\n",
        "            break\n",
        "\n",
        "        state = new_state # if  the last action do not complete the episode, then skip the conditional, move to new state &  next time step\n",
        "\n",
        "env.close() # close the environment"
      ],
      "metadata": {
        "id": "eBMoU3u5PX6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ec2d08-31e9-4afa-81ef-83f394848f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Right)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFF\u001b[41mG\u001b[0m\n",
            "\n",
            "Win\n"
          ]
        }
      ]
    }
  ]
}